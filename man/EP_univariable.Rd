% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EP_Univariable.R
\name{EP_univariable}
\alias{EP_univariable}
\title{Univariate MEP Bayes with DISCO severity (EP_univariable)}
\usage{
EP_univariable(
  data,
  predictor,
  outcome = "y",
  missing = c("complete", "impute"),
  impute_args = list(),
  n_iter = 20000,
  burn_in = 5000,
  step_hi = 0.3,
  step_lo = 0.12,
  ci_level = 0.95,
  compare = TRUE,
  return_draws = FALSE,
  seed = NULL,
  transform_beta1 = c("none", "logit", "SAS", "Long"),
  sigma0 = 10,
  sigma1_hi = 5,
  sigma1_lo = 0.15,
  kappa_min = 1,
  kappa_max = 2.5,
  tune_threshold_hi = 0.45,
  tune_threshold_lo = 0.2,
  tune_interval = 500
)
}
\arguments{
\item{data}{A data.frame containing \code{outcome} and \code{predictor}.}

\item{predictor}{String; name of the predictor column.}

\item{outcome}{String; name of the binary outcome column (default \code{"y"}).}

\item{missing}{How to handle missing data (applied \emph{once}, shared by severity
and estimation): \code{"complete"} (drop rows with any NA in
\code{predictor} or \code{outcome}) or \code{"impute"} (drop rows with NA in
\code{outcome}, and impute \code{predictor} only). Default \code{"complete"}.}

\item{impute_args}{Optional list of imputation settings used only when
\code{missing = "impute"}:
\itemize{
\item \code{numeric_method = "median"|"mean"} (default \code{"median"})
\item \code{factor_method = "mode"} (default \code{"mode"})
}}

\item{n_iter}{Integer; total MCMC iterations (including burn-in).
Default \code{20000}.}

\item{burn_in}{Integer; burn-in iterations discarded from the front.
Default \code{5000}.}

\item{step_hi, step_lo}{RW–MH proposal s.d. blended by severity as
\code{step = step_hi*(1 - severity) + step_lo*severity}.
Defaults \code{0.30} and \code{0.12}.}

\item{ci_level}{Credible interval level in (0,1). Default \code{0.95}.}

\item{compare}{Logical; if \code{TRUE} (default) fit a GLM comparator on the same rows
\emph{with standardized X} for reference.}

\item{return_draws}{Logical; if \code{TRUE}, include posterior draws on
standardized and original scales. Default \code{FALSE}.}

\item{seed}{Optional integer; if provided, sets RNG seed for reproducibility.}

\item{transform_beta1}{One of \code{"none"}, \code{"logit"}, \code{"SAS"}, \code{"Long"}.
If not \code{"none"}, also reports \code{beta0_orig} and the chosen slope on the
original predictor scale. Default \code{"none"} (standardized-only output).}

\item{sigma0}{Prior sd for intercept (logit scale). Default \code{10}.}

\item{sigma1_hi}{Prior sd for slope under mild separation (\code{severity = 0}).
Default \code{5}.}

\item{sigma1_lo}{Prior sd for slope under severe separation (\code{severity = 1}).
Default \code{0.15}.}

\item{kappa_min, kappa_max}{Exponential-power shapes at \code{severity = 0} and
\code{1}, blended linearly. Defaults \code{1} and \code{2.5}.}

\item{tune_threshold_hi, tune_threshold_lo}{Burn-in acceptance thresholds for
auto step-size tuning (increase if \code{> hi}; decrease if \code{< lo}).
Defaults \code{0.45} and \code{0.20}.}

\item{tune_interval}{Iterations between tuning checks during burn-in.
Default \code{500}.}
}
\value{
A list with components:
\itemize{
\item \code{predictor}, \code{outcome}
\item \code{disco}: list with \code{separation_type}, \code{severity_score},
\code{boundary_threshold}, \code{single_tie_boundary}, \code{missing_info}.
\item \code{prior}: list with \code{mu}, \code{Sigma}, \code{kappa},
\code{sigma0}, \code{sigma1} (slope prior scale implied by severity).
\item \code{mcmc}: list with \code{acceptance_rate}, \code{step_size_used},
\code{n_iter}, \code{burn_in}.
\item \code{posterior}: data.frame of summaries with columns \code{Param},
\code{Mean}, \code{SD}, \code{CI_low}, \code{CI_high}, containing
\code{beta0}, \code{beta1} (standardized) and, if requested via
\code{transform_beta1}, \code{beta0_orig} plus one of
\code{beta1_logit}/\code{beta1_SAS}/\code{beta1_Long}.
\item \code{comparators}: list with a \code{glm} coefficient vector (fit on standardized X)
when available.
\item \code{rows_used}: integer indices of rows used after missing handling.
\item \code{draws} (optional): list with \code{chain_std} and \code{chain_orig}
(included when \code{return_draws = TRUE}).
}
}
\description{
Runs a DISCO-based univariate separation diagnostic, constructs an adaptive
Multivariate Exponential Power (MEP) prior from the severity score, and fits
a univariate logistic model (intercept + one predictor) via random-walk
Metropolis–Hastings (RW–MH).
}
\details{
\strong{Shared missing handling.}
The \code{missing} choice is applied once to \code{(data[[outcome]], data[[predictor]])}.
With \code{missing = "complete"} we drop rows with any NA in those two columns.
With \code{missing = "impute"} we drop rows with NA in the outcome, then impute
NAs in the predictor using \code{impute_args}. The resulting rows/values are used
for both the DISCO severity and the model fit. We call
\code{DISCO::uni_separation(..., missing = "complete")} on the already-prepared data.

\strong{Scaling for consistency.}
Numeric predictors are z-scored (\emph{standardized}) for: (i) the Bayesian fit,
(ii) the GLM comparator, and (iii) the DISCO severity computation.
Factors are left unchanged in the severity step; for estimation/comparators a
2-level factor is converted to a 0/1 indicator (error if >2 levels).

\strong{Adaptive prior from severity.}
Let \eqn{\bar{y}} be the sample mean on the analyzed rows and \eqn{s_x} the
predictor SD (on those rows). The MEP prior on \eqn{(\beta_0,\beta_1)} (working,
standardized-\eqn{X} scale) uses
\deqn{\mu = (\mathrm{logit}(\bar{y}),\, 0),\quad
      \Sigma = \mathrm{diag}(\sigma_0^2,\ \sigma_1^2),\quad
      \log \sigma_1 = (1-s)\log\sigma_{1,\mathrm{hi}} + s\log\sigma_{1,\mathrm{lo}},}
with \eqn{s} the severity score from \code{DISCO::uni_separation()} and
\eqn{\kappa = \kappa_{\min} + s(\kappa_{\max} - \kappa_{\min})}.

\strong{Back-transform formulas.} If requested via \code{transform_beta1}:
\deqn{\beta_{1}^{\mathrm{logit}} = \beta_{1}^{\mathrm{std}}/s_x,\qquad
      \beta_{0}^{\mathrm{orig}} = \beta_{0}^{\mathrm{std}} - \beta_{1}^{\mathrm{std}}\cdot (\bar{x}/s_x),}
and we also report one of:
\deqn{\beta_{1}^{\mathrm{SAS}}  = \beta_{1}^{\mathrm{logit}} \cdot \pi/\sqrt{3},\qquad
      \beta_{1}^{\mathrm{Long}} = \beta_{1}^{\mathrm{logit}} \cdot (\pi/\sqrt{3} + 1).}

\strong{Tuning.} During burn-in, the RW–MH step size is multiplicatively
adapted every \code{tune_interval} iterations to aim for an acceptance rate
between \code{tune_threshold_lo} and \code{tune_threshold_hi}.
}
\section{Output conventions}{

By default, the function returns the \strong{standardized} coefficients:
\itemize{
\item \code{beta0}: intercept in the standardized-\eqn{X} (z-scored) working scale.
\item \code{beta1}: slope with respect to the standardized predictor.
}
Optionally, set \code{transform_beta1} to back-transform to the original
predictor scale, which adds:
\itemize{
\item \code{beta0_orig}: intercept on the original predictor scale.
\item \code{beta1_logit} \emph{or} \code{beta1_SAS} \emph{or} \code{beta1_Long}:
slope per 1 unit change in the original predictor, on the chosen scale.
}
}

\examples{
\donttest{
## Toy data
y <- c(0,0,0,0, 1,1,1,1)
x <- c(-0.52, -0.07, -0.60, -0.67, 1.39, 0.16, 1.40, 0.09)
df <- data.frame(y = y, x = x)

## 0) Detect Separation
detect <- DISCO::uni_separation(df, predictor = "x", outcome = "y")
detect$separation_type # e.g., "Perfect separation"

## 1) Default: STANDARDIZED coefficients (beta0, beta1)
fit_std <- EP_univariable(
  data = df, predictor = "x", outcome = "y",
  n_iter = 6000, burn_in = 2000, seed = 42
)
fit_std$posterior

## 2) Back-transform slope to ORIGINAL-x units on the LOGIT scale
fit_logit <- EP_univariable(
  data = df, predictor = "x", outcome = "y",
  transform_beta1 = "logit",
  n_iter = 6000, burn_in = 2000, seed = 42
)
fit_logit$posterior

## 3) Alternative effect scales on ORIGINAL-x units (choose ONE)
fit_sas <- EP_univariable(
  data = df, predictor = "x", outcome = "y",
  transform_beta1 = "SAS",
  n_iter = 6000, burn_in = 2000, seed = 42
)
fit_long <- EP_univariable(
  data = df, predictor = "x", outcome = "y",
  transform_beta1 = "Long",
  n_iter = 6000, burn_in = 2000, seed = 42
)
fit_sas$posterior   # contains beta1_SAS
fit_long$posterior  # contains beta1_Long

## 4) Shared missing handling
df2 <- df; df2$x[c(5, 8)] <- NA
fit_cc <- EP_univariable(df2, "x", "y", missing = "complete",
                         n_iter = 4000, burn_in = 1500, seed = 9)
fit_im <- EP_univariable(df2, "x", "y", missing = "impute",
                         impute_args = list(numeric_method = "median"),
                         n_iter = 4000, burn_in = 1500, seed = 9)
}
}
\seealso{
\code{\link[DISCO]{uni_separation}} for severity diagnostics.
}
